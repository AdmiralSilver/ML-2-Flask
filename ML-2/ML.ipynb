{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from joblib import dump"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 **Frame the problem and look at the big picture**<br>\n",
    "We refer the included report, where we discuss the objective."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 **Get the data**<br>\n",
    "Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetTrain = pd.read_csv('train.csv')\n",
    "datasetTest = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 **Explore and visualize the data to gain insights**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetTrain.info()\n",
    "#datasetTest.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetTest.head()\n",
    "datasetTrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetTrain.describe()\n",
    "datasetTest.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetTrain.isnull().sum()\n",
    "datasetTest.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop belongs_to_collection because most of the values are null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetTrain = datasetTrain.drop(['belongs_to_collection'], axis=1)\n",
    "datasetTest = datasetTest.drop(['belongs_to_collection'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop homepage because most of the values are null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetTrain = datasetTrain.drop(['homepage'], axis=1)\n",
    "datasetTest = datasetTest.drop(['homepage'], axis=1)\n",
    "print(datasetTest[datasetTest['release_date'].isnull()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The release date of the movie with id 3829 is missing, after an internet search we found that the release date is<br>\n",
    "05/01/2000<br>\n",
    "We replace the missing value with the correct one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetTest.loc[datasetTest['release_date'].isnull(), 'release_date'] = '05/01/00'\n",
    "datasetTest[datasetTest[\"release_date\"] == '5/1/00']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For nominal data (strings), we replace the missing values with \"unknown\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetTrain[['genres',\n",
    "              'original_language',\n",
    "              'production_companies',\n",
    "              'production_countries',\n",
    "              'status',\n",
    "              'cast',\n",
    "              'crew',\n",
    "              'spoken_languages',\n",
    "              ]] = datasetTrain[['genres',\n",
    "                                 'original_language',\n",
    "                                 'production_companies',\n",
    "                                 'production_countries',\n",
    "                                 'status',\n",
    "                                 'cast',\n",
    "                                 'crew',\n",
    "                                 'spoken_languages',\n",
    "                                 ]].fillna('unknown')\n",
    "datasetTest[['genres',\n",
    "             'original_language',\n",
    "             'production_companies',\n",
    "             'production_countries',\n",
    "             'status',\n",
    "             'cast',\n",
    "             'crew',\n",
    "             'spoken_languages',\n",
    "             ]] = datasetTest[['genres',\n",
    "                               'original_language',\n",
    "                               'production_companies',\n",
    "                               'production_countries',\n",
    "                               'status',\n",
    "                               'cast',\n",
    "                               'crew',\n",
    "                               'spoken_languages',\n",
    "                               ]].fillna('unknown')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For numerical data, we replace the missing values with the mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetTrain['runtime'] = datasetTrain['runtime'].fillna(datasetTrain['runtime'].mean())\n",
    "datasetTest['runtime'] = datasetTest['runtime'].fillna(datasetTest['runtime'].mean())\n",
    "print(datasetTrain['runtime'].isnull().any())\n",
    "print(datasetTest['runtime'].isnull().any())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check if there are still missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Missing values-----------------')\n",
    "print(datasetTrain.isnull().sum())\n",
    "print(datasetTest.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to convert the release_date column to datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetTrain['release_date'] = pd.to_datetime(datasetTrain['release_date'])\n",
    "datasetTest['release_date'] = pd.to_datetime(datasetTest['release_date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a new column with the year, month and day of the release date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetTrain['release_year'] = pd.to_datetime(datasetTrain['release_date']).dt.year.astype(int)\n",
    "datasetTrain['release_month'] = pd.to_datetime(datasetTrain['release_date']).dt.month.astype(int)\n",
    "datasetTrain['release_day'] = pd.to_datetime(datasetTrain['release_date']).dt.day.astype(int)\n",
    "datasetTest['release_year'] = pd.to_datetime(datasetTest['release_date']).dt.year.astype(int)\n",
    "datasetTest['release_month'] = pd.to_datetime(datasetTest['release_date']).dt.month.astype(int)\n",
    "datasetTest['release_day'] = pd.to_datetime(datasetTest['release_date']).dt.day.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We drop the release_date column since we don't need it anymore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetTrain = datasetTrain.drop(['release_date'], axis=1)\n",
    "datasetTest = datasetTest.drop(['release_date'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considering the competition was in 2019, there should not be any movies with a release date after 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Maximum release_year in train-set: \", datasetTrain['release_year'].max())\n",
    "print(\"Maximum release_year in test-set: \", datasetTest['release_year'].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that quite a few movies have a release year after 2019, seems like these movies were released in the<br>\n",
    "1900s but a mistake has swapped 19 with 20 so that a movie released in 1971 is registered as 2071<br>\n",
    "Fixing the release year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_release_year(year):\n",
    "    if year > 2019:\n",
    "        return year - 100\n",
    "    else:\n",
    "        return year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetTrain['release_year'] = datasetTrain['release_year'].apply(lambda x: fix_release_year(x))\n",
    "datasetTest['release_year'] = datasetTest['release_year'].apply(lambda x: fix_release_year(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analyzing the data**<br>\n",
    "Visualizing the budget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize': (15, 8)})\n",
    "plt.xlabel('Budget')\n",
    "plt.hist(datasetTrain['budget'], bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the plot we can see that most of the movies have low budget<br>\n",
    "Display the relation between budget and revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize': (15, 8)})\n",
    "plt.xlabel('Budget')\n",
    "plt.ylabel('Revenue')\n",
    "plt.scatter(datasetTrain['budget'], datasetTrain['revenue'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the plot we can see that there is a positive correlation between budget and revenue<br>\n",
    "Display the relation between budget and popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize': (15, 8)})\n",
    "plt.xlabel('Budget')\n",
    "plt.ylabel('Popularity')\n",
    "plt.scatter(datasetTrain['budget'], datasetTrain['popularity'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrMatrix = datasetTrain.corr()\n",
    "sns.heatmap(corrMatrix, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " From the correlation matrix we can see that there is a high positive<br>\n",
    " correlation between budget and revenue, there is also a high positive correlation between popularity and revenue,<br>\n",
    " lastly there is a positive correlation between runtime and revenue<br>\n",
    " Visualizing these correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 3, figsize=(15, 8), tight_layout=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetTrain.plot(ax=ax[0][0], x='budget', y='revenue', style='o', ylabel='Revenue', color='red').set_title(\n",
    "    'Budget vs Revenue')\n",
    "datasetTrain.plot(ax=ax[0][1], x='popularity', y='revenue', style='o', ylabel='Revenue', color='green').set_title(\n",
    "    'Popularity vs Revenue')\n",
    "datasetTrain.plot(ax=ax[0][2], x='runtime', y='revenue', style='o', ylabel='Revenue', color='blue').set_title(\n",
    "    'Runtime vs Revenue')\n",
    "datasetTrain.plot(ax=ax[1][0], x='budget', y='popularity', style='o', ylabel='Popularity', color='orange').set_title(\n",
    "    'Budget vs Popularity')\n",
    "datasetTrain.plot(ax=ax[1][1], x='budget', y='runtime', style='o', ylabel='Runtime', color='purple').set_title(\n",
    "    'Budget vs Runtime')\n",
    "datasetTrain.plot(ax=ax[1][2], x='popularity', y='runtime', style='o', ylabel='Runtime', color='brown').set_title(\n",
    "    'Popularity vs Runtime')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing the change in revenue, runtime, popularity and budget over the years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(4, 1, tight_layout=True)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetTrain.groupby('release_year')['revenue'].mean().plot(ax=ax[0], figsize=(10, 10), linewidth=3,\n",
    "                                                            color='red').set_title('Revenue over the years')\n",
    "datasetTrain.groupby('release_year')['runtime'].mean().plot(ax=ax[1], figsize=(10, 10), linewidth=3,\n",
    "                                                            color='green').set_title('Runtime over the years')\n",
    "datasetTrain.groupby('release_year')['popularity'].mean().plot(ax=ax[2], figsize=(10, 10), linewidth=3,\n",
    "                                                               color='blue').set_title('Popularity over the years')\n",
    "datasetTrain.groupby('release_year')['budget'].mean().plot(ax=ax[3], figsize=(10, 10), linewidth=3,\n",
    "                                                           color='orange').set_title('Budget over the years')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Movies with budget under 10000: \", len(datasetTrain[datasetTrain['budget'] < 10000]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there are 835 out of 300 movies that have a budget under 10000, since alot of the movies have a budget<br>\n",
    "of 0, we change this later.<br>\n",
    "# 4 **Prepare the data for Machine Learning algorithms**<br>\n",
    "Many of the features that could be useful is in JSON-format, for example the genres column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for y in enumerate(datasetTest['genres'][:10]):\n",
    "    print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting JSON to nominal format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_data(x):\n",
    "    try:\n",
    "        data = eval(x)\n",
    "    except:\n",
    "        data = {}\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetTrain.genres = datasetTrain.genres.map(lambda x: sorted([i['name'] for i in convert_data(x)])).map(\n",
    "    lambda x: ','.join(map(str, x)))\n",
    "datasetTrain.spoken_languages = datasetTrain.spoken_languages.map(\n",
    "    lambda x: sorted([i['name'] for i in convert_data(x)])).map(\n",
    "    lambda x: ','.join(map(str, x)))\n",
    "datasetTrain.crew = datasetTrain.crew.map(lambda x: sorted([i['name'] for i in convert_data(x)])).map(\n",
    "    lambda x: ','.join(map(str, x)))\n",
    "datasetTrain.cast = datasetTrain.cast.map(lambda x: sorted([i['name'] for i in convert_data(x)])).map(\n",
    "    lambda x: ','.join(map(str, x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetTest.genres = datasetTest.genres.map(lambda x: sorted([i['name'] for i in convert_data(x)])).map(\n",
    "    lambda x: ','.join(map(str, x)))\n",
    "datasetTest.spoken_languages = datasetTest.spoken_languages.map(\n",
    "    lambda x: sorted([i['name'] for i in convert_data(x)])).map(\n",
    "    lambda x: ','.join(map(str, x)))\n",
    "datasetTest.crew = datasetTest.crew.map(lambda x: sorted([i['name'] for i in convert_data(x)])).map(\n",
    "    lambda x: ','.join(map(str, x)))\n",
    "datasetTest.cast = datasetTest.cast.map(lambda x: sorted([i['name'] for i in convert_data(x)])).map(\n",
    "    lambda x: ','.join(map(str, x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(datasetTrain.crew.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a better way to visualize the data compared to the json format<br>\n",
    "But it still might be more interesting to see the amount of genres, cast members, spoken languages and crew members<br>\n",
    "to see if there is a correlation between these and the revenue<br>\n",
    "One could for example expect that a bigger crew would mean higher revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetTrain['genres_amount'] = datasetTrain['genres'].str.count(',') + 1\n",
    "datasetTrain['cast_amount'] = datasetTrain['cast'].str.count(',') + 1\n",
    "datasetTrain['spoken_languages_amount'] = datasetTrain['spoken_languages'].str.count(',') + 1\n",
    "datasetTrain['crew_amount'] = datasetTrain['crew'].str.count(',') + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetTest['genres_amount'] = datasetTest['genres'].str.count(',') + 1\n",
    "datasetTest['cast_amount'] = datasetTest['cast'].str.count(',') + 1\n",
    "datasetTest['spoken_languages_amount'] = datasetTest['spoken_languages'].str.count(',') + 1\n",
    "datasetTest['crew_amount'] = datasetTest['crew'].str.count(',') + 1\n",
    "print(datasetTest['genres_amount'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting the nominal values to numerical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetTrain[['status',\n",
    "              'original_language',\n",
    "              'production_companies',\n",
    "              'production_countries']] = datasetTrain[['status',\n",
    "                                                       'original_language',\n",
    "                                                       'production_companies',\n",
    "                                                       'production_countries']].astype('category')\n",
    "datasetTrain['status'] = datasetTrain['status'].cat.codes\n",
    "datasetTrain['original_language'] = datasetTrain['original_language'].cat.codes\n",
    "datasetTrain['production_companies'] = datasetTrain['production_companies'].cat.codes\n",
    "datasetTrain['production_countries'] = datasetTrain['production_countries'].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetTest[['status',\n",
    "             'original_language',\n",
    "             'production_companies',\n",
    "             'production_countries']] = datasetTest[['status',\n",
    "                                                     'original_language',\n",
    "                                                     'production_companies',\n",
    "                                                     'production_countries']].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetTest['status'] = datasetTest['status'].cat.codes\n",
    "datasetTest['original_language'] = datasetTest['original_language'].cat.codes\n",
    "datasetTest['production_companies'] = datasetTest['production_companies'].cat.codes\n",
    "datasetTest['production_countries'] = datasetTest['production_countries'].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(datasetTrain['production_countries'])\n",
    "# print out number of movies with budget of 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Movies with budget of 0: \", len(datasetTrain[datasetTrain['budget'] == 0]))\n",
    "# print out number of movies with runtime of 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Movies with runtime of 0:\", len(datasetTrain[datasetTrain['runtime'] == 0]))\n",
    "# We can see that a lot of movies has a budget of 0, and some of these should be high budget movies\n",
    "# It also makes no sense to have a runtime of 0\n",
    "# We will replace the 0 values with the mean of the column\n",
    "datasetTrain['budget'] = datasetTrain['budget'].replace(0, datasetTrain['budget'].mean())\n",
    "datasetTrain['runtime'] = datasetTrain['runtime'].replace(0, datasetTrain['runtime'].mean())\n",
    "datasetTest['budget'] = datasetTest['budget'].replace(0, datasetTest['budget'].mean())\n",
    "datasetTest['runtime'] = datasetTest['runtime'].replace(0, datasetTest['runtime'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New correlation matrix with the new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrMatrix = datasetTrain.corr()\n",
    "sns.heatmap(corrMatrix, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this new correlation matrix we can see that some new features are correlated with the revenue<br>\n",
    "We chose to use the following features for our model: budget, popularity, runtime, cast_amount, crew_amount<br>\n",
    "We will now try to predict the revenue using these features<br>\n",
    "Predictor variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = datasetTrain[['budget', 'popularity', 'runtime', 'cast_amount', 'crew_amount']]\n",
    "# Target variable\n",
    "y = datasetTrain['revenue']\n",
    "# Splitting the data into training and testing data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 **Explore many different models and shortlist the best ones**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will try out the following models:<br>\n",
    "Linear Regression<br>\n",
    "Decision Tree<br>\n",
    "Random Forest<br>\n",
    "Support Vector Machine<br>\n",
    "K Nearest Neighbors<br>\n",
    "Gradient Boosting<br>\n",
    "We will use the mean squared error as a metric to evaluate the models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "print(\"Linear Regression MSE: \", mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeRegressor()\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred = dt.predict(X_test)\n",
    "print(\"Decision Tree MSE: \", mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor()\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "print(\"Random Forest MSE: \", mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr = SVR()\n",
    "svr.fit(X_train, y_train)\n",
    "y_pred = svr.predict(X_test)\n",
    "print(\"Support Vector Machine MSE: \", mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsRegressor()\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "print(\"K Nearest Neighbors MSE: \", mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = GradientBoostingRegressor()\n",
    "gb.fit(X_train, y_train)\n",
    "y_pred = gb.predict(X_test)\n",
    "print(\"Gradient Boosting MSE: \", mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scores<br>\n",
    "Linear Regression MSE:        7950571505110897.0<br>\n",
    "Decision Tree MSE:            1.2655086106528986e+16<br>\n",
    "Random Forest MSE:            6706835613617110.0<br>\n",
    "Support Vector Machine MSE:   2.2173175065004816e+16<br>\n",
    "K Nearest Neighbors MSE:      9751561958431006.0<br>\n",
    "Gradient Boosting MSE:        7184735606350928.0<br>\n",
    "We can see that the Random Forest model performed the best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6**Fine-tune your models and combine them into a great solution**<br>\n",
    "We will now try to improve the model by tuning the hyperparameters<br>\n",
    "We will use RandomizedSearchCV to find the best hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of trees in random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [int(x) for x in np.linspace(start=200, stop=2000, num=10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num=11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random search of parameters, using 3-fold cross validation,<br>\n",
    "search across 100 different combinations, and use all available cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_random = RandomizedSearchCV(estimator=rf, param_distributions=random_grid, n_iter=100, cv=3, verbose=2,\n",
    "                               random_state=42, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the random search model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best parameters: \", rf_random.best_params_)\n",
    "# Best score\n",
    "print(\"Best score: \", rf_random.best_score_)\n",
    "# Best parameters {'n_estimators': 2000, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt',\n",
    "# 'max_depth': 10, 'bootstrap': False} Best score 0.688"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now use the best parameters to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(n_estimators=400, min_samples_split=10, min_samples_leaf=4, max_features='auto',\n",
    "                           max_depth=70, bootstrap=True)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "print(\"Random Forest MSE: \", mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'Id': datasetTest['id'], 'revenue': rf.predict(\n",
    "    datasetTest[['budget', 'popularity', 'runtime', 'cast_amount', 'crew_amount']])})\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(submission.head())\n",
    "# Compare the results of the model with the actual revenue with a bar chart\n",
    "barData = {'Actual revenue': y_test.mean(), 'Predicted revenue': y_pred.mean()}\n",
    "barOne = list(barData.keys())\n",
    "barTwo = list(barData.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 5))\n",
    "plt.bar(barOne, barTwo, color=['blue', 'orange'])\n",
    "plt.xlabel(\"Revenue\")\n",
    "plt.ylabel(\"Amount\")\n",
    "plt.title(\"Actual vs Predicted revenue\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now try to find out which features are the most important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = pd.DataFrame(rf.feature_importances_,\n",
    "                                   index=X_train.columns,\n",
    "                                   columns=['importance']).sort_values('importance', ascending=False)\n",
    "print(feature_importances)\n",
    "# From the results we can see that the most important features are budget and popularity. What we learn from this is\n",
    "# that the budget and popularity of a movie are the most important factors in determining the revenue of a movie. We\n",
    "# can also see that the runtime, cast amount and crew amount are not very important. Going forward we can try to\n",
    "# remove these features and see if the model performs better.\n",
    "NB_DIR = Path.cwd()\n",
    "MODEL_DIR = NB_DIR / 'models'\n",
    "dump(rf, MODEL_DIR / 'model.joblib', compress=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7 **Present your solution**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8 **Launch, monitor, and maintain your system**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}